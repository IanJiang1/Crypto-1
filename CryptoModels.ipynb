{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ebfbf99-e9d9-42af-a071-9baf4e5d0e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1867775520.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_6142/1867775520.py\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    cd ta-lib/\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# installing talib\n",
    "!tar -xzf ta-lib-0.4.0-src.tar.gz\n",
    "cd ta-lib/\n",
    "\n",
    "!./configure --prefix=/usr\n",
    "\n",
    "!make\n",
    "\n",
    "!sudo make install\n",
    "\n",
    "cd ../\n",
    "\n",
    "!pip install TA-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d23596-2a85-45ab-9e3b-21462bc81ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in /opt/conda/lib/python3.7/site-packages (1.26.1)\n",
      "Requirement already satisfied: databricks-cli>=0.8.7 in /opt/conda/lib/python3.7/site-packages (from mlflow) (0.17.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.3.5)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from mlflow) (2022.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/lib/python3.7/site-packages (from mlflow) (2.1.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from mlflow) (21.3)\n",
      "Requirement already satisfied: querystring-parser in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.2.4)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.5.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from mlflow) (5.4.1)\n",
      "Requirement already satisfied: docker>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (5.0.3)\n",
      "Requirement already satisfied: gitpython>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (3.1.27)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (3.20.1)\n",
      "Requirement already satisfied: requests>=2.17.3 in /opt/conda/lib/python3.7/site-packages (from mlflow) (2.27.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from mlflow) (0.4)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /opt/conda/lib/python3.7/site-packages (from mlflow) (4.11.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.21.6)\n",
      "Requirement already satisfied: Flask in /opt/conda/lib/python3.7/site-packages (from mlflow) (2.1.2)\n",
      "Requirement already satisfied: sqlparse>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from mlflow) (0.4.2)\n",
      "Requirement already satisfied: prometheus-flask-exporter in /opt/conda/lib/python3.7/site-packages (from mlflow) (0.20.2)\n",
      "Requirement already satisfied: gunicorn in /opt/conda/lib/python3.7/site-packages (from mlflow) (20.1.0)\n",
      "Requirement already satisfied: alembic in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.8.0)\n",
      "Requirement already satisfied: sqlalchemy in /opt/conda/lib/python3.7/site-packages (from mlflow) (1.4.36)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.10)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (1.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (3.2.0)\n",
      "Requirement already satisfied: pyjwt>=1.7.0 in /opt/conda/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (2.4.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from docker>=4.0.0->mlflow) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (4.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (4.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (3.3)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.7/site-packages (from alembic->mlflow) (5.7.1)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.7/site-packages (from alembic->mlflow) (1.2.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy->mlflow) (1.1.2)\n",
      "Requirement already satisfied: Werkzeug>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow) (2.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow) (2.1.2)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /opt/conda/lib/python3.7/site-packages (from Flask->mlflow) (3.1.2)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/conda/lib/python3.7/site-packages (from gunicorn->mlflow) (59.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->mlflow) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->mlflow) (2.8.2)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow) (0.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (3.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from Jinja2>=3.0->Flask->mlflow) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43cb1a2f-9e2d-46a0-afa4-59064973686f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dtw-python in /opt/conda/lib/python3.7/site-packages (1.1.14)\n",
      "Requirement already satisfied: numpy>=1.19 in /opt/conda/lib/python3.7/site-packages (from dtw-python) (1.21.6)\n",
      "Requirement already satisfied: scipy>=1.1 in /opt/conda/lib/python3.7/site-packages (from dtw-python) (1.5.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install dtw-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7a00a4-36b3-4d96-910d-9a03a54a4d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kneed in /opt/conda/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.2 in /opt/conda/lib/python3.7/site-packages (from kneed) (1.21.6)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from kneed) (1.5.4)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from kneed) (3.5.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (9.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->kneed) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->kneed) (4.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->kneed) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edadf262-240f-4602-ae1b-bc80b8236d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snowflake-connector-python in /opt/conda/lib/python3.7/site-packages (2.7.9)\n",
      "Requirement already satisfied: cryptography<37.0.0,>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (36.0.2)\n",
      "Requirement already satisfied: pycryptodomex!=3.5.0,<4.0.0,>=3.2 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (3.15.0)\n",
      "Requirement already satisfied: oscrypto<2.0.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (1.3.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (1.5.1)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (2.4.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (3.3)\n",
      "Requirement already satisfied: requests<3.0.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (2.27.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (2022.5.18.1)\n",
      "Requirement already satisfied: setuptools>34.0.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (59.8.0)\n",
      "Requirement already satisfied: pyOpenSSL<23.0.0,>=16.2.0 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (22.0.0)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (1.15.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from snowflake-connector-python) (2022.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python) (2.21)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0->snowflake-connector-python) (1.26.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install snowflake-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7d37e9f-3677-4f05-a3ea-e627c55222a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llvmlite\n",
      "  Using cached llvmlite-0.38.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "Installing collected packages: llvmlite\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: [Errno 28] No space left on device\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install llvmlite --ignore-installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60652fa7-b5be-4945-8a78-fb1e971e6bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycaret in /opt/conda/lib/python3.7/site-packages (3.0.0rc2)\n",
      "Requirement already satisfied: pmdarima>=1.8.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.8.5)\n",
      "Requirement already satisfied: schemdraw>=0.14 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.15)\n",
      "Requirement already satisfied: numba~=0.55.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.55.1)\n",
      "Requirement already satisfied: requests>=2.27.1 in /opt/conda/lib/python3.7/site-packages (from pycaret) (2.27.1)\n",
      "Requirement already satisfied: scipy<1.9.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.5.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (3.5.2)\n",
      "Requirement already satisfied: numpy~=1.21 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.21.6)\n",
      "Requirement already satisfied: statsmodels>=0.12.1 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.13.2)\n",
      "Requirement already satisfied: yellowbrick>=1.4 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.4)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.9.0)\n",
      "Requirement already satisfied: psutil>=5.9.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (5.9.1)\n",
      "Requirement already satisfied: tbats>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from pycaret) (4.64.0)\n",
      "Requirement already satisfied: pandas<1.5.0,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.3.5)\n",
      "Requirement already satisfied: ipywidgets>=7.6.5 in /opt/conda/lib/python3.7/site-packages (from pycaret) (8.0.0rc0)\n",
      "Requirement already satisfied: kaleido>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.2.1)\n",
      "Requirement already satisfied: pyod>=0.9.8 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.0.2)\n",
      "Requirement already satisfied: joblib>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.1.0)\n",
      "Requirement already satisfied: jinja2>=1.2 in /opt/conda/lib/python3.7/site-packages (from pycaret) (3.1.2)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (5.9.0)\n",
      "Requirement already satisfied: scikit-plot>=0.3.7 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.3.7)\n",
      "Requirement already satisfied: ipython>=5.5.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (7.33.0)\n",
      "Requirement already satisfied: lightgbm>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (3.3.2)\n",
      "Requirement already satisfied: category-encoders>=2.4.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (2.5.0)\n",
      "Requirement already satisfied: sktime>=0.11.4 in /opt/conda/lib/python3.7/site-packages (from pycaret) (0.12.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.7/site-packages (from pycaret) (1.0.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /opt/conda/lib/python3.7/site-packages (from category-encoders>=2.4.0->pycaret) (0.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from imbalanced-learn>=0.8.1->pycaret) (3.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (3.0.29)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (59.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (0.1.3)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (5.2.1.post0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (2.12.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.6.5->pycaret) (5.4.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0rc0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.6.5->pycaret) (3.0.0rc0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.6.5->pycaret) (6.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0rc0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets>=7.6.5->pycaret) (4.0.0rc0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2>=1.2->pycaret) (2.1.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from lightgbm>=3.0.0->pycaret) (0.37.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret) (9.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=3.3.0->pycaret) (4.33.3)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /opt/conda/lib/python3.7/site-packages (from numba~=0.55.0->pycaret) (0.38.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas<1.5.0,>=1.3.0->pycaret) (2022.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from plotly>=5.0.0->pycaret) (8.0.1)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.7/site-packages (from pmdarima>=1.8.0->pycaret) (1.26.9)\n",
      "Requirement already satisfied: Cython!=0.29.18,>=0.29 in /opt/conda/lib/python3.7/site-packages (from pmdarima>=1.8.0->pycaret) (3.0.0a10)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pyod>=0.9.8->pycaret) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.27.1->pycaret) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.27.1->pycaret) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.27.1->pycaret) (2022.5.18.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from schemdraw>=0.14->pycaret) (4.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /opt/conda/lib/python3.7/site-packages (from sktime>=0.11.4->pycaret) (1.2.13)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from deprecated>=1.2.13->sktime>=0.11.4->pycaret) (1.14.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (7.3.1)\n",
      "Requirement already satisfied: debugpy>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (1.6.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (1.5.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.3)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (4.10.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (4.5.1)\n",
      "Requirement already satisfied: fastjsonschema in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (2.15.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.5)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (21.4.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (4.11.4)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (5.7.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (0.18.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (0.4)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (23.0.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.7/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat>=4.2.0->ipywidgets>=7.6.5->pycaret) (3.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --pre pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c95c3a75-f037-4cbc-bee8-ce39b2546ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow==6.0.0 in /opt/conda/lib/python3.7/site-packages (6.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /opt/conda/lib/python3.7/site-packages (from pyarrow==6.0.0) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow==6.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbb61da4-4c1a-476f-ade8-d8a3c282fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_utils import preprocess1, get_all_indices\n",
    "from formatting_utils import load_all_format_components_gcs, data_formatter\n",
    "from modeling_utils import get_split_dates, pycaret_automl, prepare_data, split_df, add_target, get_cross_corr_matrix\n",
    "import yaml\n",
    "import snowflake.connector\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from data_loading_utils import load_crypto, crypto_filter_times\n",
    "\n",
    "# import time\n",
    "# from kneed import DataGenerator, KneeLocator\n",
    "# from sklearn.ensemble import IsolationForest\n",
    "# from scipy.stats import rankdata\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# from snowflake.connector.pandas_tools import write_pandas\n",
    "# import snowflake.connector\n",
    "# import pandas as pd\n",
    "# import yaml\n",
    "# from datetime import datetime\n",
    "# from getpass import getpass\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.cluster import KMeans\n",
    "# from tqdm import tqdm\n",
    "# from itertools import combinations\n",
    "# import warnings\n",
    "# from pycaret.classification import *\n",
    "import traceback\n",
    "# import gcsfs\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "#===========================================================\n",
    "#====================FEATURE ENGINEERING====================\n",
    "#===========================================================\n",
    "\n",
    "# def clusterize(df, cluster_num=2):\n",
    "#     def find_cluster_num(data, max_clusters=10):\n",
    "#         sse = {}\n",
    "#         for k in range(1, max_clusters + 1):\n",
    "#             kmeans = KMeans(n_clusters=k)\n",
    "#             kmeans.fit(data)\n",
    "#             sse[k] = kmeans.inertia_\n",
    "#         kn = KneeLocator(x=list(sse.keys()), \n",
    "#                   y=list(sse.values()), \n",
    "#                   curve='convex', \n",
    "#                   direction='decreasing')\n",
    "#         return kn.knee \n",
    "#     df_out= df.copy()\n",
    "#     clust_model_dict = {}\n",
    "#     order_dict = {}\n",
    "#     for col in tqdm(df.columns):\n",
    "#         col_output = df[col]\n",
    "#         col_output = col_output.replace([np.inf, -np.inf], np.nan)\n",
    "#         with warnings.catch_warnings():\n",
    "#             warnings.simplefilter(\"ignore\")\n",
    "#             if cluster_num is None:\n",
    "#                 cluster_num_tmp = find_cluster_num(col_output.dropna().values.reshape(-1, 1))\n",
    "#             else:\n",
    "#                 cluster_num_tmp = cluster_num\n",
    "#             kmeans = KMeans(n_clusters=cluster_num_tmp).fit(col_output.dropna().values.reshape(-1, 1))\n",
    "#             clust_model_dict[col] = kmeans\n",
    "#             order_map = dict(zip(range(cluster_num_tmp), np.squeeze(rankdata(kmeans.cluster_centers_)).tolist()))\n",
    "#             col_output[~col_output.isna()] = list(map(lambda x: order_map[x], kmeans.labels_))\n",
    "#             order_dict[col] = order_map\n",
    "#         df_out[col] = col_output\n",
    "#     return df_out, clust_model_dict, order_dict\n",
    "\n",
    "\n",
    "#===============================================\n",
    "#====================PYCARET====================\n",
    "#===============================================\n",
    "\n",
    "# def pycaret_automl(crypto_train, crypto_test, coin, return_period, \n",
    "#                    plot=True, download=False, save_folder=\"/content/drive/MyDrive/crypto_models\",\n",
    "#                    pycaret_setup_args=None,\n",
    "#                    pycaret_compare_args=None):\n",
    "#     # Setting up environment\n",
    "#     # CRITICAL: Out-of-time validation scheme\n",
    "#     if pycaret_setup_args is None:\n",
    "#         exp_default = setup(data=crypto_train, test_data=crypto_test, target=\"target\", log_experiment=True, \n",
    "#                             experiment_name=\"{}_{}\".format(coin, return_period),)\n",
    "#     else:\n",
    "\n",
    "#         exp_default = setup(data=crypto_train, test_data=crypto_test, target=\"target\", log_experiment=True, \n",
    "#                     experiment_name=\"{}_{}\".format(coin, return_period), **pycaret_setup_args)\n",
    "    \n",
    "#     if save_folder is not None:\n",
    "#         if os.path.exists(save_folder):\n",
    "#             pass\n",
    "#         else:\n",
    "#             os.makedirs(save_folder)\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     if pycaret_compare_args is None:\n",
    "#         best_models = compare_models(n_select=5, sort=\"AUC\", exclude=[\"gbc\"])\n",
    "#     else:\n",
    "#         if \"include\" in pycaret_compare_args:\n",
    "#             best_models = compare_models(n_select=5, sort=\"AUC\", **pycaret_compare_args)\n",
    "#         else:\n",
    "#             best_models = compare_models(n_select=5, sort=\"AUC\", exclude=[\"gbc\"], **pycaret_compare_args)\n",
    "#     print(\"Completed in {} seconds\".format(time.time() - start_time))\n",
    "\n",
    "#     if download:\n",
    "#         files.download(mld_name + \".pkl\")\n",
    "  \n",
    "#     best_model = best_models[0]# Selecting best model\n",
    "\n",
    "#     if plot:\n",
    "#         print(\"========================================================================================================================================\")\n",
    "#         print(\"===============================================================BEST MODEL===============================================================\")\n",
    "#         print(\"========================================================================================================================================\")\n",
    "#         plot_model(best_model)\n",
    "#         plot_model(best_model, plot=\"confusion_matrix\")\n",
    "\n",
    "#         print(\"========================================================================================================================================\")\n",
    "#         print(\"===============================================================BEST BLEND===============================================================\")\n",
    "#         print(\"========================================================================================================================================\")\n",
    "#         plot_model(best_models_blend)\n",
    "#         plot_model(best_models_blend, plot=\"confusion_matrix\")\n",
    "      \n",
    "#     # Finalizing best model(s)\n",
    "#     best_model_finalized = finalize_model(best_model)\n",
    "  \n",
    "#     if save_folder is not None:\n",
    "#         if save_folder.endswith(\"/\"):\n",
    "#             get_logs().to_csv(save_folder + \"{}_{}_log.csv\".format(coin, return_period))\n",
    "#             save_model(best_model_finalized, save_folder + \"best_model_finalized\")\n",
    "#         else:\n",
    "#             get_logs().to_csv(save_folder + \"/{}_{}_log.csv\".format(coin, return_period))\n",
    "#             save_model(best_model_finalized, save_folder + \"/best_model_finalized\")\n",
    "#     else:\n",
    "#         save_model(best_model_finalized, \"best_model_finalized\")\n",
    "#         get_logs().to_csv(\"{}_{}_log.csv\".format(coin, return_period))\n",
    "  \n",
    "#     return best_models, best_model_finalized, get_logs()\n",
    "\n",
    "\n",
    "\n",
    "#=========================================================\n",
    "#====================CROSS-CORRELATION====================\n",
    "#=========================================================\n",
    "\n",
    "# def cross_corr(crypto_wide, coin1, coin2, lag):\n",
    "#     if lag > 0:\n",
    "#         return(np.corrcoef(crypto_wide.dropna(subset=[coin1, coin2])[coin1].iloc[lag:], crypto_wide.dropna(subset=[coin1, coin2])[coin2].shift(lag).dropna())[0, 1])\n",
    "#     elif lag < 0:\n",
    "#         return(np.corrcoef(crypto_wide.dropna(subset=[coin1, coin2])[coin1].iloc[:lag], crypto_wide.dropna(subset=[coin1, coin2])[coin2].shift(lag).dropna())[0, 1])\n",
    "#     elif lag == 0:\n",
    "#         return(np.corrcoef(crypto_wide.dropna(subset=[coin1, coin2])[coin1], crypto_wide.dropna(subset=[coin1, coin2])[coin2])[0, 1])\n",
    "\n",
    "\n",
    "# def cross_corr_range(crypto_wide, coin1, coin2, lag_range, plot=True):\n",
    "#     result = pd.Series(lag_range).apply(lambda x: cross_corr(crypto_wide, coin1, coin2, int(round(x))))\n",
    "#     result.index = lag_range\n",
    "#     if plot:\n",
    "#         plt.plot(result)\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         pass\n",
    "#     return result\n",
    "\n",
    "\n",
    "# def get_cross_corr_matrix(crypto_wide, price_cols, num_est = 10):\n",
    "#     cross_corr_mat = pd.DataFrame([], columns=price_cols, index=price_cols)\n",
    "#     print(\"Getting cross-correlations\")\n",
    "#     print(\"\\t\", end=\"\")\n",
    "#     for pair in tqdm(list(combinations(price_cols, 2))):\n",
    "#         cross_corr_values = cross_corr_range(crypto_wide, pair[0], pair[1], np.linspace(-2880, 2880, num=num_est), plot=False)\n",
    "#         greatest_result = cross_corr_values[cross_corr_values == cross_corr_values.max()]\n",
    "#         greatest_lag = greatest_result.index[0]\n",
    "#         greatest_corr = greatest_result.values[0]\n",
    "#         if greatest_lag < 0:\n",
    "#             cross_corr_mat.loc[pair[0], pair[1]] = greatest_corr\n",
    "#         elif greatest_lag > 0:\n",
    "#             cross_corr_mat.loc[pair[1], pair[0]] = greatest_corr\n",
    "#         else:\n",
    "#             pass\n",
    "#     return cross_corr_mat.astype(float)\n",
    "\n",
    "\n",
    "# def get_split_dates(crypto_wide, num_weeks_train, num_weeks_test, num_weeks_holdout):\n",
    "#     # Defining our periods of interest\n",
    "#     holdout_start = crypto_wide.index.max() - pd.Timedelta(weeks=num_weeks_holdout)\n",
    "#     test_start = holdout_start - pd.Timedelta(weeks=num_weeks_test)\n",
    "#     train_start = test_start - pd.Timedelta(weeks=num_weeks_train)\n",
    "#     print(\"Number of training samples: {}\".format(((crypto_wide.index < test_start) & (crypto_wide.index >= train_start)).sum()))\n",
    "#     print(\"Number of test samples: {}\".format(((crypto_wide.index >= test_start) & (crypto_wide.index < holdout_start)).sum()))\n",
    "#     print(\"Number of holdout samples: {}\".format(((crypto_wide.index >= holdout_start)).sum()))\n",
    "#     return train_start, test_start, holdout_start\n",
    "\n",
    "\n",
    "# def prepare_data(crypto_wide, coin_of_interest, columns_of_interest, train_start, test_start, holdout_start, cluster_num=None, \n",
    "#                   cross_correlation_matrix=None, cross_corr_thresh=0.50, outlier_column=False):\n",
    "#     all_coins = [coin_of_interest]\n",
    "\n",
    "#     # Yielding our testing/training/holdout dataframes\n",
    "#     crypto_train = crypto_wide.loc[train_start:test_start]\n",
    "#     crypto_test = crypto_wide.loc[test_start:holdout_start]\n",
    "#     crypto_holdout = crypto_wide.loc[holdout_start:]\n",
    "#     crypto_test_holdout = pd.concat([crypto_test, crypto_holdout])\n",
    "\n",
    "#     # Getting clusters for each coin return\n",
    "#     print(\"Fitting clusters on training data\")\n",
    "#     print(\"\\t\", end=\"\")\n",
    "#     cluster_cols = [col for col in crypto_train if \"{}_pct_change\".format(coin_of_interest) in col]\n",
    "#     crypto_return_clusters_train, cluster_model_dict, order_dict = clusterize(crypto_wide.loc[train_start:test_start, cluster_cols], cluster_num=cluster_num)\n",
    "# #     crypto_return_clusters_train = crypto_return_clusters_train.loc[train_start:]\n",
    "#     crypto_return_clusters_test_holdout = crypto_test_holdout[cluster_cols].copy()\n",
    "\n",
    "#     print(\"Predicting clusters on test and holdout data\")\n",
    "#     print(\"\\t\", end=\"\")\n",
    "#     for col in tqdm(cluster_cols):\n",
    "#         kmean_labels = cluster_model_dict[col].predict(crypto_return_clusters_test_holdout[col].values.reshape(-1, 1))\n",
    "#         crypto_return_clusters_test_holdout[col] = list(map(lambda x: order_dict[col][x], kmean_labels))\n",
    "    \n",
    "#     crypto_return_clusters_train = crypto_return_clusters_train.astype(int).astype(str)\n",
    "#     crypto_return_clusters_test_holdout = crypto_return_clusters_test_holdout.astype(int).astype(str)\n",
    "#     crypto_train = crypto_train.join(crypto_return_clusters_train, lsuffix=\"\", rsuffix=\"_clust\")\n",
    "#     crypto_test_holdout = crypto_test_holdout.join(crypto_return_clusters_test_holdout, lsuffix=\"\", rsuffix=\"_clust\")\n",
    "#     columns_of_interest += [col for col in crypto_train if \"clust\" in col]\n",
    "  \n",
    "#     # Adding coin data for potentially causal coins\n",
    "#     if cross_correlation_matrix is not None:\n",
    "#         print(\"Getting additional potentially influential coins\")\n",
    "#         print(\"\\t\", end=\"\")\n",
    "#         additional_coins = (cross_correlation_matrix.abs() > cross_corr_thresh).query(coin_of_interest).index.tolist()\n",
    "#         all_coins += additional_coins\n",
    "#         additional_cols = []\n",
    "#         for coin in tqdm(additional_coins):\n",
    "#             additional_cols += [col for col in crypto_train if coin in col]\n",
    "#         columns_of_interest += additional_cols\n",
    "#         columns_of_interest = list(set(columns_of_interest))\n",
    "#     else:\n",
    "#         pass\n",
    "  \n",
    "#     # Getting coin-based outliers\n",
    "#     if outlier_column:\n",
    "#         print(\"Getting outliers\")\n",
    "#         print(\"\\t\", end=\"\")\n",
    "#         outlier_dict = {}\n",
    "#         for coin in tqdm(all_coins):\n",
    "#             # Getting coin-related columns to create outlier computation\n",
    "#             coin_cols = [col for col in crypto_wide if coin in col]\n",
    "\n",
    "#             # training the model\n",
    "#             clf = IsolationForest(max_samples=100, random_state=1)\n",
    "#             clf.fit(crypto_train[coin_cols].replace([np.inf, -np.inf], np.nan).dropna().values)\n",
    "#             outlier_dict[coin] = (clf, coin_cols)\n",
    "#             train_outliers = clf.predict(crypto_train[coin_cols].replace([np.inf, -np.inf], np.nan).dropna().values)\n",
    "#             outlier_col = \"{}_OUTLIER\".format(coin)\n",
    "#             columns_of_interest += [outlier_col]\n",
    "#             crypto_train[outlier_col] = np.nan\n",
    "#             crypto_train.loc[~crypto_train[coin_cols].replace([np.inf, -np.inf], np.nan).isna().any(axis=1), outlier_col] = train_outliers.astype(int).astype(str)\n",
    "\n",
    "#             # predicting model on test/holdout partitions\n",
    "#             test_outliers = clf.predict(crypto_test_holdout[coin_cols].replace([np.inf, -np.inf], np.nan).dropna().values)\n",
    "#             crypto_test_holdout[outlier_col] = np.nan\n",
    "#             crypto_test_holdout.loc[~crypto_test_holdout[coin_cols].replace([np.inf, -np.inf], np.nan).isna().any(axis=1), outlier_col] = test_outliers.astype(int).astype(str)\n",
    "  \n",
    "#     # Selecting only our columns of interest\n",
    "#     crypto_train = crypto_train[columns_of_interest]\n",
    "#     crypto_test_holdout = crypto_test_holdout[columns_of_interest]\n",
    "#     return crypto_train, crypto_test_holdout, crypto_return_clusters_train, crypto_return_clusters_test_holdout, \\\n",
    "#             cluster_model_dict, outlier_dict\n",
    "\n",
    "\n",
    "# def add_target(coin_of_interest, crypto_train, crypto_test_holdout, return_period, test_start):\n",
    "#     # Joining on clusters of our coin returns\n",
    "#     target = \"{}_pct_change_{}\".format(coin_of_interest, return_period)\n",
    "#     combined_df = pd.concat([crypto_train, crypto_test_holdout])\n",
    "#     combined_cluster_df = pd.concat([crypto_return_clusters_train, crypto_return_clusters_test_holdout])\n",
    "#     combined_df = combined_df[~combined_df.index.duplicated(keep='first')]\n",
    "#     combined_cluster_df = combined_cluster_df[~combined_cluster_df.index.duplicated(keep='first')]\n",
    "#     combined_df[\"target\"] = combined_cluster_df[target].shift(-return_period)\n",
    "#     crypto_train, crypto_test_holdout = combined_df.loc[:test_start], combined_df.loc[test_start:]\n",
    "#     cluster_desc = crypto_train.groupby(crypto_return_clusters_train[target])[[target]].describe()\n",
    "#     print(\"Unique values of target: {}\".format(crypto_train[\"target\"].nunique()))\n",
    "#     return crypto_train, crypto_test_holdout, cluster_desc\n",
    "\n",
    "\n",
    "# def split_df(crypto_train, crypto_test_holdout, holdout_start):\n",
    "#     # Further partitioning our combined test/holdout dataframe\n",
    "#     crypto_test, crypto_holdout = crypto_test_holdout.loc[:holdout_start].dropna(subset=[\"target\"]), crypto_test_holdout.loc[holdout_start:].dropna(subset=[\"target\"])\n",
    "\n",
    "#     # Converting target to string for classification task\n",
    "#     crypto_train[\"target\"] = crypto_train[\"target\"].astype(int).astype(str)\n",
    "#     crypto_test[\"target\"] = crypto_test[\"target\"].astype(int).astype(str)\n",
    "#     crypto_test[\"target\"] = crypto_test[\"target\"].astype(int).astype(str)\n",
    "#     return crypto_train, crypto_test, crypto_holdout\n",
    "\n",
    "\n",
    "\n",
    "#=============================================================\n",
    "#====================BACKTESTING UTILITIES====================\n",
    "#=============================================================\n",
    "\n",
    "class TimeFrame():\n",
    "    def __init__(self, data=None, index_col=None):\n",
    "        \"\"\"Initializing data\"\"\"\n",
    "        if data is None:\n",
    "            self.data = pd.DataFrame()\n",
    "        else:\n",
    "            self.data = data\n",
    "            if index_col is None:\n",
    "                pass\n",
    "            else:\n",
    "                self.data.set_index(index_col)\n",
    "        if (self.data.index.dtype.__str__() in ['datetime64[ns]', 'datetime64']) or (self.data.empty):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Requires one-dimensional datetime index\")\n",
    "            raise ValueError(\"index not datetime error\")\n",
    "    \n",
    "    \n",
    "    def check_datetime_index(self):\n",
    "        \"\"\"Check and enforce the main data index to a single-dimensional datetime\"\"\"\n",
    "        if (self.data.index.dtype.__str__() in ['datetime64[ns]', 'datetime64']) or (self.data.empty):\n",
    "            pass\n",
    "        else:\n",
    "            print(\"Requires one-dimensional datetime index\")\n",
    "            raise ValueError(\"index not datetime error\")\n",
    "            \n",
    "            \n",
    "    def add_data(self, data, index_col=None, values=None, lsuffix=None, rsuffix=None):\n",
    "        \"\"\"Joining another data source onto main data\"\"\"\n",
    "        if not self.data.empty:\n",
    "            if index_col is None:\n",
    "                self.data = self.data.join(data, lsuffix=lsuffix, rsuffix=rsuffix)\n",
    "            else:\n",
    "                self.data = self.data.join(data.set_index(index_col), lsuffix=lsuffix, rsuffix=rsuffix)\n",
    "        else:\n",
    "            self.data = data\n",
    "            if index_col is None:\n",
    "                pass\n",
    "            else:\n",
    "                self.data.set_index(index_col)\n",
    "        self.check_datetime_index()\n",
    "    \n",
    "    \n",
    "    def load_data(self, fname, index_col=None):\n",
    "        \"\"\"Add data by loading a local csv\"\"\"\n",
    "        data = pd.read_csv(fname)\n",
    "        self.add_data(data, index_col=index_col)\n",
    "    \n",
    "    \n",
    "    def multiply(self, col1, col2, out=None):\n",
    "        \"\"\"Multiply two columns together\"\"\"\n",
    "        if out is None:\n",
    "            out = col1 + \"_times_\" + col2\n",
    "        self.data[out] = self.data[col1] * self.data[col2]\n",
    "        self.check_datetime_index()\n",
    "        \n",
    "    \n",
    "    def divide(self, col1, col2, out=None):\n",
    "        \"\"\"Dividing two columns\"\"\"\n",
    "        if out is None:\n",
    "            out = col1 + \"_by_\" + col2\n",
    "        self.data[out] = self.data[col1] / self.data[col2].replace(0, np.nan)\n",
    "        self.check_datetime_index()\n",
    "    \n",
    "    \n",
    "    def aggregate(self, index_col=None, agg_dict=None):\n",
    "        \"\"\"Aggregate data at a specific level\"\"\"\n",
    "        if index_col is None:\n",
    "            groupby_col = self.data.index\n",
    "        else:\n",
    "            groupby_col = self.data[index_col]\n",
    "        \n",
    "        numeric_cols = self.data.dtypes[self.data.dtypes == float].index.tolist()\n",
    "        if agg_dict is None:\n",
    "            self.data = self.data.groupby(groupby_col)[[numeric_cols]].sum()\n",
    "        else:\n",
    "            self.data = self.data.groupby(groupby_col).agg(agg_dict)\n",
    "        self.check_datetime_index()\n",
    "\n",
    "\n",
    "class StockStrategy(TimeFrame):\n",
    "    def __init__(self, data, price_col):\n",
    "        super().__init__(data)\n",
    "        self.price_col = price_col\n",
    "        \n",
    "        # Initializing with a null strategy\n",
    "        self.signals = pd.DataFrame(index=data.index).sort_index()\n",
    "        self.signals[\"signal\"] = 0.0   \n",
    "    \n",
    "    \n",
    "    #---------------------GENERATING STRATEGIES-------------------------\n",
    "    #-------------------------------------------------------------------\n",
    "    def generic_query_strategy(self, query=None, exit_query=None, plot=False):\n",
    "        \"\"\"Creating a generic strategy based upon input query.\n",
    "           Running this method will erase the current strategy attribute\n",
    "           and build a replacement\"\"\"\n",
    "        if query is None:\n",
    "            if hasattr(self, \"strategy_query\"):\n",
    "                query = self.strategy_query\n",
    "            else:\n",
    "                raise\n",
    "        \n",
    "        if exit_query is None:\n",
    "            if hasattr(self, \"exit_query\"):\n",
    "                exit_query = self.exit_query\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        self.signals = pd.DataFrame(index=self.data.index).sort_index()\n",
    "        self.signals[\"signal\"] = 0.0\n",
    "        \n",
    "        if exit_query is not None:\n",
    "            buy_ind = self.data.query(query).index\n",
    "            sell_ind = self.data.query(exit_query).index\n",
    "            buy_sell = pd.Series(self.data.index.isin(buy_ind), index=self.data.index).map({True:1, False:np.nan})\n",
    "            sell_times = pd.Series(self.data.index.isin(sell_ind), index=self.data.index).map({True:-1, False:np.nan}).dropna()\n",
    "            buy_sell = pd.concat([sell_times, buy_sell])\n",
    "            buy_sell = buy_sell[~buy_sell.index.duplicated(keep=\"first\")]\n",
    "            buy_sell = buy_sell.sort_index()\n",
    "\n",
    "            curr_signal = 0\n",
    "            signal_ind = []\n",
    "            \n",
    "            #\n",
    "            # TODO: Vectorized Implementation\n",
    "            #\n",
    "            \n",
    "            for x in buy_sell.iteritems():\n",
    "                if x[1] == 1:\n",
    "                    curr_signal = 1\n",
    "                elif x[1] == -1:\n",
    "                    curr_signal = 0\n",
    "                else:\n",
    "                    pass\n",
    "                signal_ind.append(curr_signal)\n",
    "\n",
    "            hold_signal = pd.Series(signal_ind, index=buy_sell.index)\n",
    "            self.signals.loc[hold_signal.astype(bool)] = 1\n",
    "        else:\n",
    "            self.signals.loc[self.data.query(query).index] = 1\n",
    "        self.signals = self.signals.sort_index()        \n",
    "        self.signals[\"positions\"] = self.signals[\"signal\"].diff()\n",
    "        self.strategy_query = query\n",
    "        if exit_query is None:\n",
    "            self.exit_query = \"~({})\".format(query)\n",
    "        else:\n",
    "            self.exit_query = exit_query\n",
    "        \n",
    "        if plot:\n",
    "            fig, ax = plt.subplots()\n",
    "            fig.set_size_inches(18.5, 10.5)\n",
    "            self.data[self.price_col].sort_index().reset_index().astype({\"Time\":str}).set_index(\"Time\").plot(ax=ax)\n",
    "            ax2 = ax.twinx()\n",
    "            self.signals[\"signal\"].sort_index().reset_index().astype({\"Time\":str}).set_index(\"Time\").plot(ax=ax2, color=\"pink\")\n",
    "\n",
    "    \n",
    "    #---------------------BACKTESTING STRATEGIES-------------------------\n",
    "    #--------------------------------------------------------------------\n",
    "    def generate_portfolio(self, portfolio_df=None, price_col=None):\n",
    "        \"\"\"Creating basic portfolio attribute for object -- set of consecutive, historical prices and strategy\n",
    "           positions as binary values -- 1/0 corresponding to hold/no-hold\"\"\"\n",
    "        if price_col is not None:\n",
    "            self.price_col = price_col\n",
    "        \n",
    "        if portfolio_df is None:\n",
    "            portfolio_out_df = self.signals.copy()\n",
    "            portfolio_out_df[self.price_col] = self.data[self.price_col]\n",
    "            portfolio_out_df[\"base_return\"] = portfolio_out_df[self.price_col].pct_change()\n",
    "            self.portfolio = portfolio_out_df.astype({self.price_col:float, \"base_return\":float})\n",
    "        else:\n",
    "            portfolio_out_df = portfolio_df.copy()\n",
    "            portfolio_out_df.index.names = [\"Time\"]\n",
    "            portfolio_out_df.sort_index(inplace=True)\n",
    "            if \"positions\" in portfolio_out_df:\n",
    "                pass\n",
    "            else:\n",
    "                portfolio_out_df[\"positions\"] = portfolio_out_df[\"signal\"].diff()\n",
    "            self.portfolio = portfolio_out_df.astype({self.price_col:float, \"base_return\":float})\n",
    "    \n",
    "    \n",
    "    def track_portfolio(self, initial_capital, shares_per_position, price_col=None, portfolio=None):\n",
    "        \"\"\"Method to execute strategy over portfolio attribute. Once portfolio and strategy are in place\n",
    "           this method will track the performance of the resulting strategy\"\"\"\n",
    "        if portfolio is None:\n",
    "            if hasattr(self, \"portfolio\"):\n",
    "                portfolio = self.portfolio\n",
    "            else:\n",
    "                raise\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        portfolio_out = portfolio.copy()\n",
    "        if price_col is not None:\n",
    "            self.price_col = price_col\n",
    "        cash = initial_capital\n",
    "        stock = 0\n",
    "        stock_hist = [stock]\n",
    "        cash_hist = [cash]\n",
    "        currently_holding = False\n",
    "        count = 0\n",
    "\n",
    "        for row in portfolio.iterrows():\n",
    "            test = row[1]\n",
    "            hold = bool(test[\"signal\"])\n",
    "            if currently_holding:\n",
    "                stock = stock * (1 + test[\"base_return\"])                    \n",
    "                if not hold:\n",
    "                    if shares_per_position:\n",
    "                        cash += stock\n",
    "                        stock = 0\n",
    "                    else:\n",
    "                        cash = stock\n",
    "                        stock = 0\n",
    "                    currently_holding = False\n",
    "            else:\n",
    "                if hold:\n",
    "                    if shares_per_position:\n",
    "                        stock = shares_per_position*test[self.price_col]\n",
    "                        if count > 0:\n",
    "                            cash -= stock\n",
    "                    else:\n",
    "                        stock = cash\n",
    "                        cash = 0\n",
    "                    currently_holding = True\n",
    "            cash_hist.append(cash)\n",
    "            stock_hist.append(stock)\n",
    "            count += 1\n",
    "        \n",
    "        portfolio_out[\"cash\"], portfolio_out[\"stock\"] = cash_hist[1:], stock_hist[1:]\n",
    "        portfolio_out[\"total\"] = portfolio_out[\"cash\"] + portfolio_out[\"stock\"]\n",
    "        portfolio_out[\"returns\"] = portfolio_out[\"total\"].pct_change()\n",
    "        return portfolio_out\n",
    "    \n",
    "    \n",
    "    def backtest(self, initial_capital=10000, shares_per_position=100, transaction_fee=0.0, regenerate_portfolio=False, \\\n",
    "                 price_col=None):\n",
    "        if hasattr(self, \"portfolio\"):\n",
    "            if regenerate_portfolio:\n",
    "                self.generate_portfolio(price_col=price_col)\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            self.generate_portfolio(price_col=price_col)\n",
    "        portfolio_out = self.track_portfolio(initial_capital, shares_per_position, price_col=price_col, portfolio=None)\n",
    "        self.portfolio = portfolio_out\n",
    "    \n",
    "    \n",
    "    def plot_backtest(self, date):\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        ax1 = fig.add_subplot(111, ylabel='Portfolio value in $')\n",
    "        ax2 = ax1.twinx()\n",
    "        \n",
    "        if date == \"all\":\n",
    "            day_portfolio = self.portfolio.sort_index().reset_index().astype({\"Time\":str}).set_index(\"Time\")\n",
    "            day_signals = self.signals.sort_index().reset_index().astype({\"Time\":str}).set_index(\"Time\")\n",
    "        else:\n",
    "            day_portfolio = self.portfolio.loc[self.portfolio.index.date == pd.Timestamp(date)]\n",
    "            day_signals = self.signals.loc[self.signals.index.date == pd.Timestamp(date)]\n",
    "\n",
    "        # Plot the equity curve in dollars\n",
    "        day_portfolio['total'].plot(ax=ax1, lw=2.0)\n",
    "        day_portfolio[self.price_col].plot(ax=ax2, color=\"orange\")\n",
    "\n",
    "        # Plot the \"buy\" trades against the equity curve\n",
    "        if date != \"all\":\n",
    "            ax1.plot(day_portfolio.loc[day_signals.positions == 1.0].index, \n",
    "                     day_portfolio.total[day_signals.positions == 1.0],\n",
    "                     '^', markersize=10, color='m')\n",
    "\n",
    "            # Plot the \"sell\" trades against the equity curve\n",
    "            ax1.plot(day_portfolio.loc[day_signals.positions == -1.0].index, \n",
    "                     day_portfolio.total[day_signals.positions == -1.0],\n",
    "                     'v', markersize=10, color='k')\n",
    "        plt.title(\"Portfolio Value for {}\".format(date))\n",
    "\n",
    "        # Show the plot\n",
    "        plt.show()\n",
    "        \n",
    "    #----------------------EVALUATING STRATEGIES-------------------------\n",
    "    #--------------------------------------------------------------------\n",
    "    def evaluate_strategy(self, metric):\n",
    "        if metric == \"sharpe\":\n",
    "            # Isolate the returns of your strategy\n",
    "            returns = self.portfolio['returns']\n",
    "\n",
    "            # annualized Sharpe ratio\n",
    "            sharpe_ratio = np.sqrt(len(returns)) * (returns.mean() / returns.std())\n",
    "\n",
    "            # Print the Sharpe ratio\n",
    "            return sharpe_ratio\n",
    "        elif metric == \"max drawdown\":\n",
    "            # Define a trailing 252 trading day window\n",
    "            window = 60\n",
    "            \n",
    "            # Calculate the max drawdown in the past window days for each day\n",
    "            rolling_max = self.portfolio[\"total\"].sort_index().rolling(window, min_periods=1).max()\n",
    "            hourly_drawdown = self.portfolio[\"total\"]/rolling_max - 1.0\n",
    "\n",
    "            # Calculate the minimum (negative) daily drawdown\n",
    "            max_hourly_drawdown = hourly_drawdown.rolling(window, min_periods=1).min()\n",
    "\n",
    "            # Plot the results\n",
    "            hourly_drawdown.plot()\n",
    "            max_hourly_drawdown.plot()\n",
    "\n",
    "            # Show the plot\n",
    "            plt.show()\n",
    "        elif metric == \"cdgr\":\n",
    "            # Get the number of days in `aapl`\n",
    "            mins = pd.Timedelta(self.portfolio.index[-1] - self.portfolio.index[0]).seconds/60\n",
    "\n",
    "            # Calculate the CAGR\n",
    "            cdgr = ((((self.portfolio[self.price_col][-1]) / self.portfolio[self.price_col][1])) ** (3600/mins)) - 1\n",
    "\n",
    "            # Print CAGR\n",
    "            return cdgr\n",
    "        \n",
    "        elif metric == \"compound_return\":\n",
    "            returns =  (self.portfolio.returns + 1).cumprod() - 1\n",
    "            baseline_returns = (self.portfolio[self.price_col].pct_change() + 1).cumprod() - 1\n",
    "            baseline_final = baseline_returns[-1]\n",
    "            portfolio_final = returns[-1]\n",
    "            print(\"Baseline Asset Returns: {}%\".format(round(baseline_returns[-1] * 100, 1)))\n",
    "            print(\"Portfolio Returns: {}%\".format(round(returns[-1] * 100, 1)))\n",
    "            return returns[-1]\n",
    "        \n",
    "    \n",
    "    #-------------------SAVING & LOADING STRATEGIES----------------------\n",
    "    #--------------------------------------------------------------------\n",
    "    def save_strategy(self, filename=\"strategy.yaml\"):\n",
    "        f = open(filename, \"w+\")\n",
    "        f.write(\"---\\n\")\n",
    "        f.write(\"enter query: {}\\n\".format(self.strategy_query))\n",
    "        f.write(\"exit query: {}\\n\".format(self.exit_query))\n",
    "        f.close()\n",
    "    \n",
    "    \n",
    "    def load_strategy(self, filename=\"strategy.yaml\"):\n",
    "        # Reading in strategy queries\n",
    "        with open(filename, \"r\") as stream:\n",
    "            try:\n",
    "                strategy = yaml.safe_load(stream)\n",
    "            except yaml.YAMLError as exc:\n",
    "                print(exc)\n",
    "        query = strategy[\"enter query\"]\n",
    "        exit_query = strategy[\"exit query\"]\n",
    "        self.strategy_query = query\n",
    "        if exit_query is None:\n",
    "            self.exit_query = \"~({})\".format(query)\n",
    "        else:\n",
    "            self.exit_query = exit_query\n",
    "    \n",
    "    \n",
    "    #---------------------------PLOTTING------------------------------\n",
    "    #-----------------------------------------------------------------\n",
    "    def plot_prices(self, date):\n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(18.5, 10.5)\n",
    "        ax1 = fig.add_subplot(111, ylabel='Portfolio value in $')\n",
    "        date_df = self.data.loc[self.data.index.date == pd.Timestamp(date)]\n",
    "        date_df[self.price_col].plot(ax=ax1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266bdb4-4656-4324-a2f8-3ad2fb125f15",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82aa9867-e84b-40fd-9aaa-799a1aa4e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "crypto_df = load_crypto(account=\"kga72450.us-east-1\",\n",
    "                            warehouse=\"COMPUTE_WH\",\n",
    "                            database=\"CRYPTO\",\n",
    "                            schema=\"PUBLIC\",\n",
    "                            start_date_str=\"2022-04-01\",\n",
    "                            end_date_str=None,\n",
    "                            snowflake_yaml=\"snowflake_key.yaml\",\n",
    "                            )\n",
    "\n",
    "# Pivoting long to wide\n",
    "crypto_wide, price_cols = preprocess1(crypto_df)\n",
    "crypto_wide = crypto_wide.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ced6d-e801-4758-9ff3-a83574fa6558",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bda7edb-ccef-41b7-af02-a348e0d37b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_cols = ['AVAXUSDT', 'BATUSDT', 'BTCUSDT', 'CHZUSDT', 'DOTUSDT', 'ENJUSDT', 'ETHUSDT', 'FTMUSDT', 'GALAUSDT', 'LINKUSDT', 'LRCUSDT', 'MANAUSDT', 'MATICUSDT', 'SOLUSDT']\n",
    "num_weeks_train, num_weeks_test, num_weeks_holdout = 4, 1, 1\n",
    "train_start, test_start, holdout_start = get_split_dates(crypto_wide, num_weeks_train, num_weeks_test, num_weeks_holdout)\n",
    "\n",
    "cross_corr_mat = get_cross_corr_matrix(crypto_wide.loc[train_start:test_start], price_cols, num_est=10)\n",
    "\n",
    "coin_dict = {}\n",
    "\n",
    "exception_dict = {}\n",
    "for coin_of_interest in set(price_cols):\n",
    "    crypto_train, crypto_test_holdout, crypto_return_clusters_train, crypto_return_clusters_test_holdout, \\\n",
    "    cluster_model_dict, outlier_model_dict = prepare_data(crypto_wide, coin_of_interest, [col for col in crypto_wide if (\"BTCUSDT\" in col) or (\"ETHUSDT\" in col) or (coin_of_interest in col)], train_start=train_start, test_start=test_start, holdout_start=holdout_start, cluster_num=None, \n",
    "                      cross_correlation_matrix=cross_corr_mat, cross_corr_thresh=0.50, outlier_column=True)\n",
    "    holdout_strategy = crypto_test_holdout.sort_index().loc[holdout_start:]\n",
    "    coin_dict[coin_of_interest] = {\"cluster_models\":cluster_model_dict, \"outlier_models\":outlier_model_dict, \"holdout\":holdout_strategy}\n",
    "    return_periods = [5, 10, 60, 180]\n",
    "    test_args = {\"fold_strategy\":\"timeseries\", \"fold\":3,}\n",
    "    compare_args = {\"include\":[\"lr\", \"lda\", \"nb\", \"ada\", \"lightgbm\", \"ridge\",]}\n",
    "    exception_dict[coin_of_interest] = {}\n",
    "    for return_period in return_periods:\n",
    "        crypto_train_tmp, crypto_test_holdout_tmp, cluster_desc = add_target(coin_of_interest, crypto_train, crypto_test_holdout, return_period, test_start, crypto_return_clusters_train, crypto_return_clusters_test_holdout)\n",
    "        crypto_train_tmp, crypto_test_tmp, crypto_holdout_tmp = split_df(crypto_train_tmp, crypto_test_holdout_tmp, holdout_start)\n",
    "        try:\n",
    "            best_models, best_model_finalized, logs = pycaret_automl(crypto_train_tmp, crypto_test_tmp, coin_of_interest, return_period, plot=False, download=False, save_folder=\"./crypto_models_1/{}/{}\".format(coin_of_interest, return_period),\n",
    "                                                                                              pycaret_setup_args=test_args,\n",
    "                                                                                              pycaret_compare_args=compare_args)\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            exception_dict[coin_of_interest][return_period] = Exception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c1efa8e-33c0-439e-b399-2a6cd812cd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2022-06-19 00:00:00')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05a7f54-36c4-482a-9c50-ad0305bc051e",
   "metadata": {},
   "source": [
    "### Uploading to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35b3ef-83b1-47b6-b585-c304d11c3b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import glob\n",
    "\n",
    "storage_client = storage.Client(project='crypto-341122')\n",
    "bucket = storage_client.bucket(\"crypto-models-1\")\n",
    "\n",
    "for local_file in tqdm(glob.glob('./crypto_models/*/*/*'), bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}'):\n",
    "    blob = bucket.blob(local_file)\n",
    "    blob.upload_from_filename(local_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb02cea-ed4d-4352-af55-bd1f7d87a9e7",
   "metadata": {},
   "source": [
    "# Crypto Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49034805-32ba-40a4-b040-c150020423d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_time = lambda x: datetime.fromtimestamp(float(x)/1000)\n",
    "\n",
    "def crypto_filter_times(crypto_df, date_str):\n",
    "    return crypto_df.loc[crypto_df.OPEN_TIME.apply(convert_time) >= date_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "999f9cc3-35ea-4b7e-b693-556e9e9558c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "crypto_test = crypto_filter_times(crypto_df, holdout_start.strftime(\"%Y-%m-%d\"))\n",
    "coin_dict = load_all_format_components_gcs(project=\"crypto-341122\", bucket_name=\"formatter\",)\n",
    "crypto_formatted = data_formatter(\"ETHUSDT\", crypto_test, coin_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32dcc0eb-e532-4936-86b6-2f31cc9e6150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-09 14:18:37.457206: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-09 14:18:37.457264: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439def6d-1b41-466d-a49e-77128423e939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVAXUSDT</th>\n",
       "      <th>BATUSDT</th>\n",
       "      <th>BTCUSDT</th>\n",
       "      <th>CHZUSDT</th>\n",
       "      <th>DOTUSDT</th>\n",
       "      <th>ENJUSDT</th>\n",
       "      <th>ETHUSDT</th>\n",
       "      <th>FTMUSDT</th>\n",
       "      <th>GALAUSDT</th>\n",
       "      <th>LINKUSDT</th>\n",
       "      <th>...</th>\n",
       "      <th>ETHUSDT_pct_change_5_clust</th>\n",
       "      <th>ETHUSDT_pct_change_60_clust</th>\n",
       "      <th>AVAXUSDT_OUTLIER</th>\n",
       "      <th>DOTUSDT_OUTLIER</th>\n",
       "      <th>ETHUSDT_OUTLIER</th>\n",
       "      <th>GALAUSDT_OUTLIER</th>\n",
       "      <th>ETHUSDT_PRED_5</th>\n",
       "      <th>ETHUSDT_PRED_10</th>\n",
       "      <th>ETHUSDT_PRED_60</th>\n",
       "      <th>ETHUSDT_PRED_180</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-19 03:00:00</th>\n",
       "      <td>14.21</td>\n",
       "      <td>0.3005</td>\n",
       "      <td>18380.10</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.401</td>\n",
       "      <td>950.70</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.05177</td>\n",
       "      <td>5.92</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 03:01:00</th>\n",
       "      <td>14.22</td>\n",
       "      <td>0.3006</td>\n",
       "      <td>18393.07</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.401</td>\n",
       "      <td>951.60</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.05181</td>\n",
       "      <td>5.94</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 03:02:00</th>\n",
       "      <td>14.23</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>18421.69</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.401</td>\n",
       "      <td>953.15</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.05187</td>\n",
       "      <td>5.94</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 03:03:00</th>\n",
       "      <td>14.24</td>\n",
       "      <td>0.3012</td>\n",
       "      <td>18435.77</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.401</td>\n",
       "      <td>954.04</td>\n",
       "      <td>0.2150</td>\n",
       "      <td>0.05188</td>\n",
       "      <td>5.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-19 03:04:00</th>\n",
       "      <td>14.28</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>18471.54</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.402</td>\n",
       "      <td>956.01</td>\n",
       "      <td>0.2157</td>\n",
       "      <td>0.05201</td>\n",
       "      <td>5.99</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:56:00</th>\n",
       "      <td>21.35</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>21516.95</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.587</td>\n",
       "      <td>1244.11</td>\n",
       "      <td>0.3023</td>\n",
       "      <td>0.06911</td>\n",
       "      <td>7.28</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:57:00</th>\n",
       "      <td>21.39</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>21513.58</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.587</td>\n",
       "      <td>1243.94</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.06897</td>\n",
       "      <td>7.28</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:58:00</th>\n",
       "      <td>21.41</td>\n",
       "      <td>0.4315</td>\n",
       "      <td>21532.58</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1245.08</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.06918</td>\n",
       "      <td>7.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-25 23:59:00</th>\n",
       "      <td>21.35</td>\n",
       "      <td>0.4311</td>\n",
       "      <td>21476.42</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>8.13</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1241.84</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.06890</td>\n",
       "      <td>7.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-26 00:00:00</th>\n",
       "      <td>21.37</td>\n",
       "      <td>0.4310</td>\n",
       "      <td>21491.18</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.586</td>\n",
       "      <td>1242.31</td>\n",
       "      <td>0.3066</td>\n",
       "      <td>0.06886</td>\n",
       "      <td>7.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9901 rows  532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AVAXUSDT  BATUSDT   BTCUSDT  CHZUSDT  DOTUSDT  ENJUSDT  \\\n",
       "Time                                                                          \n",
       "2022-06-19 03:00:00     14.21   0.3005  18380.10   0.0841     6.90    0.401   \n",
       "2022-06-19 03:01:00     14.22   0.3006  18393.07   0.0842     6.90    0.401   \n",
       "2022-06-19 03:02:00     14.23   0.3012  18421.69   0.0844     6.91    0.401   \n",
       "2022-06-19 03:03:00     14.24   0.3012  18435.77   0.0844     6.90    0.401   \n",
       "2022-06-19 03:04:00     14.28   0.3023  18471.54   0.0845     6.92    0.402   \n",
       "...                       ...      ...       ...      ...      ...      ...   \n",
       "2022-06-25 23:56:00     21.35   0.4309  21516.95   0.1051     8.14    0.587   \n",
       "2022-06-25 23:57:00     21.39   0.4309  21513.58   0.1051     8.14    0.587   \n",
       "2022-06-25 23:58:00     21.41   0.4315  21532.58   0.1052     8.16    0.589   \n",
       "2022-06-25 23:59:00     21.35   0.4311  21476.42   0.1050     8.13    0.585   \n",
       "2022-06-26 00:00:00     21.37   0.4310  21491.18   0.1049     8.14    0.586   \n",
       "\n",
       "                     ETHUSDT  FTMUSDT  GALAUSDT  LINKUSDT  ...  \\\n",
       "Time                                                       ...   \n",
       "2022-06-19 03:00:00   950.70   0.2149   0.05177      5.92  ...   \n",
       "2022-06-19 03:01:00   951.60   0.2150   0.05181      5.94  ...   \n",
       "2022-06-19 03:02:00   953.15   0.2150   0.05187      5.94  ...   \n",
       "2022-06-19 03:03:00   954.04   0.2150   0.05188      5.94  ...   \n",
       "2022-06-19 03:04:00   956.01   0.2157   0.05201      5.99  ...   \n",
       "...                      ...      ...       ...       ...  ...   \n",
       "2022-06-25 23:56:00  1244.11   0.3023   0.06911      7.28  ...   \n",
       "2022-06-25 23:57:00  1243.94   0.3025   0.06897      7.28  ...   \n",
       "2022-06-25 23:58:00  1245.08   0.3051   0.06918      7.28  ...   \n",
       "2022-06-25 23:59:00  1241.84   0.3059   0.06890      7.27  ...   \n",
       "2022-06-26 00:00:00  1242.31   0.3066   0.06886      7.27  ...   \n",
       "\n",
       "                     ETHUSDT_pct_change_5_clust  ETHUSDT_pct_change_60_clust  \\\n",
       "Time                                                                           \n",
       "2022-06-19 03:00:00                         2.0                          0.0   \n",
       "2022-06-19 03:01:00                         2.0                          0.0   \n",
       "2022-06-19 03:02:00                         2.0                          0.0   \n",
       "2022-06-19 03:03:00                         0.0                          0.0   \n",
       "2022-06-19 03:04:00                         1.0                          0.0   \n",
       "...                                         ...                          ...   \n",
       "2022-06-25 23:56:00                         1.0                          3.0   \n",
       "2022-06-25 23:57:00                         1.0                          3.0   \n",
       "2022-06-25 23:58:00                         0.0                          3.0   \n",
       "2022-06-25 23:59:00                         0.0                          3.0   \n",
       "2022-06-26 00:00:00                         0.0                          3.0   \n",
       "\n",
       "                     AVAXUSDT_OUTLIER  DOTUSDT_OUTLIER  ETHUSDT_OUTLIER  \\\n",
       "Time                                                                      \n",
       "2022-06-19 03:00:00              -1.0             -1.0             -1.0   \n",
       "2022-06-19 03:01:00              -1.0             -1.0             -1.0   \n",
       "2022-06-19 03:02:00              -1.0             -1.0             -1.0   \n",
       "2022-06-19 03:03:00              -1.0             -1.0             -1.0   \n",
       "2022-06-19 03:04:00              -1.0             -1.0             -1.0   \n",
       "...                               ...              ...              ...   \n",
       "2022-06-25 23:56:00               1.0             -1.0             -1.0   \n",
       "2022-06-25 23:57:00              -1.0             -1.0             -1.0   \n",
       "2022-06-25 23:58:00              -1.0             -1.0             -1.0   \n",
       "2022-06-25 23:59:00               1.0             -1.0             -1.0   \n",
       "2022-06-26 00:00:00              -1.0             -1.0              NaN   \n",
       "\n",
       "                     GALAUSDT_OUTLIER  ETHUSDT_PRED_5  ETHUSDT_PRED_10  \\\n",
       "Time                                                                     \n",
       "2022-06-19 03:00:00              -1.0               1                1   \n",
       "2022-06-19 03:01:00              -1.0               1                1   \n",
       "2022-06-19 03:02:00              -1.0               2                2   \n",
       "2022-06-19 03:03:00              -1.0               2                2   \n",
       "2022-06-19 03:04:00              -1.0               2                2   \n",
       "...                               ...             ...              ...   \n",
       "2022-06-25 23:56:00              -1.0               2                2   \n",
       "2022-06-25 23:57:00              -1.0             NaN              NaN   \n",
       "2022-06-25 23:58:00              -1.0               2                2   \n",
       "2022-06-25 23:59:00              -1.0               3                1   \n",
       "2022-06-26 00:00:00              -1.0             NaN              NaN   \n",
       "\n",
       "                     ETHUSDT_PRED_60  ETHUSDT_PRED_180  \n",
       "Time                                                    \n",
       "2022-06-19 03:00:00                4                 3  \n",
       "2022-06-19 03:01:00                4                 3  \n",
       "2022-06-19 03:02:00                3                 3  \n",
       "2022-06-19 03:03:00                3                 3  \n",
       "2022-06-19 03:04:00                3                 3  \n",
       "...                              ...               ...  \n",
       "2022-06-25 23:56:00                4                 3  \n",
       "2022-06-25 23:57:00              NaN               NaN  \n",
       "2022-06-25 23:58:00                4                 3  \n",
       "2022-06-25 23:59:00                4                 3  \n",
       "2022-06-26 00:00:00              NaN               NaN  \n",
       "\n",
       "[9901 rows x 532 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crypto_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fd5ee05-c3c6-4f52-bf37-d05762bc428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow) (21.3)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow) (59.8.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m123.7/123.7 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.21.6)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.46.3)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.1 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (4.2.0)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.6.6)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.5.18.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=1dd0d828e376f2caa3e9851ad9f17f28cc53c3174c1d93fcc02e5bff8f1edd6d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/3f/e3/ec/8a8336ff196023622fbcb36de0c5a5c218cbb24111d1d4c7f2\n",
      "Successfully built termcolor\n",
      "Installing collected packages: termcolor, tensorboard-plugin-wit, libclang, keras, flatbuffers, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, absl-py, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.1\n",
      "    Uninstalling protobuf-3.20.1:\n",
      "      Successfully uninstalled protobuf-3.20.1\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.5.1\n",
      "    Uninstalling google-auth-oauthlib-0.5.1:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.5.1\n",
      "Successfully installed absl-py-1.1.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 h5py-3.7.0 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 opt-einsum-3.3.0 protobuf-3.19.4 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e28bc5-0523-475d-b505-1b7733c5e6ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Strategy Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f3f354-188a-4425-92cb-73db4f18d5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting\n",
    "coin_of_interest = \"BTCUSDT\"\n",
    "strategy = StockStrategy(crypto_formatted.loc[\"2022-06-01\":], coin_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ff237-f1df-4405-bcc3-715c8b74c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strategy.generic_query_strategy(\"BTCUSDT >= BTCUSDT_UP_2 + 200\", exit_query=\"BTCUSDT <= BTCUSDT_LOW_2\", plot=True)\n",
    "strategy.generic_query_strategy(\"BTCUSDT >= BTCUSDT_UP_2 + 200\", plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a0ee74-eb07-48a2-bece-5ee1dbe86e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Purely prediction-based strategy\n",
    "strategy.backtest(initial_capital=100, shares_per_position=None, transaction_fee=0.0)\n",
    "strategy.plot_backtest(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd28e65-74a1-49cd-88df-b80a1b6601ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
